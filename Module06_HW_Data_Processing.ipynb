{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/franklin-univ-data-science/comp411/blob/master/Module05_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXPcet9fooe0"
   },
   "source": [
    "## Homework 6\n",
    "\n",
    "1. In the given data set, identify the number of missing values by column; fill the missing values by most frequent number (hint: you need strategy='most_frequent').\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "csv_data = \\\n",
    "'''\n",
    "col1,col2\n",
    ",2.0\n",
    ",\n",
    "10.0,11.0\n",
    "1, 3 \n",
    "1, 11\n",
    "'''\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df\n",
    "```\n",
    "2. Explain the transformer and estimator in sci-kit learn. What are the differences between them?\n",
    "3. In the given data set, generate the dummy variables for the categorical variables using one-hot encoding. \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "df = pd.DataFrame(np.random.rand(10, 2),\n",
    "                 columns = ['col1', 'col2'])\n",
    "df['col3'] = list(''.join(np.random.choice(list('abc')) for _ in range(len(df))))\n",
    "df\n",
    "```\n",
    "4. Assume col3 is the target, separate the original data set in #3 into 80% training and 20% test.\n",
    "5. Load sci-kit learn's diabetes data set by **load_diabetes()**, pick the top 3 most discriminative features using Random Forest (hint: pick the correct method base on the machine learning type)\n",
    "\n",
    "```python\n",
    "\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "```\n",
    "6. In two to three paragraphs of prose (i.e. sentences, not bullet lists), summarize and interact with the content that was covered this week in readings and in class meeting. In your summary, you should highlight the major topics, methods, and practices that were covered. Your summary should also interact with the material through personal observations, reflections, and applications to the field of study. In particular, highlight what surprised, enlightened, or otherwise engaged you. In other words, you should think and write critically not just about what was presented but also what you have learned through the session. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 1. 11.]\n",
      " [10. 11.]\n",
      " [ 1.  3.]\n",
      " [ 1. 11.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "csv_data = \\\n",
    "'''\n",
    "col1,col2\n",
    ",2.0\n",
    ",\n",
    "10.0,11.0\n",
    "1, 3 \n",
    "1, 11\n",
    "'''\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df\n",
    "df.isnull().sum()\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "print(imp.fit_transform(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformer is ski-kit learn is used to change the input data that is the x variable. The estimator will use the data that is given to x to predict the value that will be set for the y variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.286139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.226851</td>\n",
       "      <td>0.551315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.719469</td>\n",
       "      <td>0.423106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.980764</td>\n",
       "      <td>0.684830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.480932</td>\n",
       "      <td>0.392118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.343178</td>\n",
       "      <td>0.729050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.438572</td>\n",
       "      <td>0.059678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.398044</td>\n",
       "      <td>0.737995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.182492</td>\n",
       "      <td>0.175452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.531551</td>\n",
       "      <td>0.531828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       col1      col2\n",
       "0  0.696469  0.286139\n",
       "1  0.226851  0.551315\n",
       "2  0.719469  0.423106\n",
       "3  0.980764  0.684830\n",
       "4  0.480932  0.392118\n",
       "5  0.343178  0.729050\n",
       "6  0.438572  0.059678\n",
       "7  0.398044  0.737995\n",
       "8  0.182492  0.175452\n",
       "9  0.531551  0.531828"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "df = pd.DataFrame(np.random.rand(10, 2),\n",
    "                 columns = ['col1', 'col2'])\n",
    "df['col3'] = list(''.join(np.random.choice(list('abc')) for _ in range(len(df))))\n",
    "df\n",
    "pd.get_dummies(df[['col1', 'col2']], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df.iloc[:, 1:].values, df.iloc[:, 0].values \n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12407834 0.12282849 0.11274263]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(importances[indices[:3]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week we worked on how to handle data sets that are missing values, how it is seperated into training and test sets, and then how to find meaningful features. To see if we have missing data we can start by looking at the table itself or calling the df.isnull().sum() which gives the number of null data points in each column making it easier to spot for larger data sets. I was surprised that we are able to fill in the data after we split the data but it makes sense as we can use the method for retrieving the data points in the training and apply it to the test set. The meaningful data can vary such as determining which data set is more likely to deal with overfitting or using the random forests to find the feature importance."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Module05_HW.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
